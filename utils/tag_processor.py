"""
íƒœê·¸ ë¶„ì„ ë° ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import numpy as np
import json
from .landmark_calculator import calculate_length


def get_tag_groups():
    """íƒœê·¸ ê·¸ë£¹ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return {
        "ì¶”ìƒ - ë¶„ìœ„ê¸°": ['ì„¸ë ¨ëœ', 'ì¹œê·¼í•œ'],
        "ì¶”ìƒ - í’ˆê²©": ['ê³ ê¸‰ìŠ¤ëŸ¬ìš´', 'ìƒê¸°ìˆëŠ”'],
        "ì¶”ìƒ - ì‹œëŒ€ê°": ['í˜„ëŒ€ì ì¸','ê³ ì „ì ì¸'],
        "ì¶”ìƒ - ì‹ ë¢°ê°": ['ë¯¿ìŒì§í•œ','ë‚ í‹°ë‚˜ëŠ”'],
        "1ì°¨ - ë™ë¬¼ìƒ": ['ê°•ì•„ì§€','ê³ ì–‘ì´','ë‹¤ëŒì¥','ì°¸ìƒˆ','ì‚¬ìŠ´'],
        "1ì°¨ - ì§€ì—­ê°": ['ì´êµ­ì ì¸','ë™ì–‘ì ì¸'],
        "1ì°¨ - ì„±ë³„ê°": ['ë‚¨ì„±ì ','ì¤‘ì„±ì ','ì—¬ì„±ìŠ¤ëŸ°'],
        "1ì°¨ - ë§¤ë ¥": ['ê·€ì—¬ìš´', 'ì²­ìˆœí•œ', 'ì„¹ì‹œí•œ'],
        "1ì°¨ - ì—°ë ¹ê°": ['ë™ì•ˆì˜', 'ì„±ìˆ™í•œ'],
        "1ì°¨ - í™”ë ¤í•¨": ['í™”ë ¤í•œ','ìˆ˜ìˆ˜í•œ'],
        "1ì°¨ - ì˜¨ë„ê°": ['ì°¨ê°€ìš´','ë”°ëœ»í•œ'],
        "1ì°¨ - ì„±ê²©": ['ì§€ì ì¸','ë°œë„í•œ'],
        "1ì°¨ - ì¸ìƒ": ['ë‚ ì¹´ë¡œìš´','ë¶€ë“œëŸ¬ìš´'],
        "1ì°¨ - ì–¼êµ´í˜•": ['ì‹œì›ì‹œì›í•œ','ë‘ë¶€ìƒ'],
        "1ì°¨ - ì„±í–¥": ['ê³ ì§‘ìˆëŠ”','ì„œê¸€ì„œê¸€í•œ'],
        "2ì°¨ - ì´ë§ˆ": ['forehead-ë†’ì´-ê¸´', 'forehead-ë†’ì´-ë³´í†µ', 'forehead-ë†’ì´-ì§§ì€', 'forehead-ë„ˆë¹„-ë„“ì€', 'forehead-ë„ˆë¹„-ë³´í†µ', 'forehead-ë„ˆë¹„-ì¢ì€'],
        "2ì°¨ - ëˆˆì¹": ['eyebrow-ëˆˆê³¼ì˜ê±°ë¦¬-ë¨¼', 'eyebrow-ëˆˆê³¼ì˜ê±°ë¦¬-ë³´í†µ', 'eyebrow-ëˆˆê³¼ì˜ê±°ë¦¬-ê°€ê¹Œìš´', 'eyebrow-í˜•íƒœ-ê³µê²©', 'eyebrow-í˜•íƒœ-ì•„ì¹˜', 'eyebrow-í˜•íƒœ-ë¬¼ê²°', 'eyebrow-í˜•íƒœ-ì¼ì', 'eyebrow-í˜•íƒœ-ë‘¥ê·¼', 'eyebrow-í˜•íƒœ-ì²˜ì§„', 'eyebrow-ê³¡ë¥ -í°', 'eyebrow-ê³¡ë¥ -ë³´í†µ', 'eyebrow-ê³¡ë¥ -ì‘ì€', 'eyebrow-ê±°ë¦¬-ë¨¼', 'eyebrow-ê±°ë¦¬-ë³´í†µ', 'eyebrow-ê±°ë¦¬-ê°€ê¹Œìš´', 'eyebrow-ê¸¸ì´-ê¸´', 'eyebrow-ê¸¸ì´-ë³´í†µ', 'eyebrow-ê¸¸ì´-ì§§ì€', 'eyebrow-ë‘ê»˜-ë‘êº¼ìš´', 'eyebrow-ë‘ê»˜-ë³´í†µ', 'eyebrow-ë‘ê»˜-ì–‡ì€', 'eyebrow-ìˆ±-ì§„í•œ', 'eyebrow-ìˆ±-ë³´í†µ', 'eyebrow-ìˆ±-íë¦°'],
        "2ì°¨ - ëˆˆ": ['eye-ì¸ìƒ-ì‚¬ë‚˜ìš´', 'eye-ì¸ìƒ-ë˜˜ë§ë˜˜ë§í•œ', 'eye-ì¸ìƒ-ë³´í†µ', 'eye-ì¸ìƒ-ìˆœí•œ', 'eye-ì¸ìƒ-ì¡¸ë¦°', 'eye-ë¯¸ê°„-ë¨¼', 'eye-ë¯¸ê°„-ë³´í†µ', 'eye-ë¯¸ê°„-ì¢ì€', 'eye-ëª¨ì–‘-ì‹œì›í•œ', 'eye-ëª¨ì–‘-ì°¢ì–´ì§„', 'eye-ëª¨ì–‘-ë³´í†µ', 'eye-ëª¨ì–‘-ë™ê·¸ë€', 'eye-ëª¨ì–‘-ë‹µë‹µí•œ', 'eye-í¬ê¸°-í°', 'eye-í¬ê¸°-ë³´í†µ', 'eye-í¬ê¸°-ì‘ì€', 'eye-ê¸¸ì´-ê¸´', 'eye-ê¸¸ì´-ë³´í†µ', 'eye-ê¸¸ì´-ì§§ì€', 'eye-ë†’ì´-ë†’ì€', 'eye-ë†’ì´-ë³´í†µ', 'eye-ë†’ì´-ë‚®ì€', 'eye-ìŒêº¼í’€-ì—†ìŒ', 'eye-ìŒêº¼í’€-ì•„ì›ƒ', 'eye-ìŒêº¼í’€-ì„¸ë¯¸ì•„ì›ƒ', 'eye-ìŒêº¼í’€-ì¸ì•„ì›ƒ', 'eye-ìŒêº¼í’€-ì¸', 'eye-ì• êµ-ë§ì€', 'eye-ì• êµ-ë³´í†µ', 'eye-ì• êµ-ì ì€', 'eye-ëˆˆë°‘ì§€-ì‹¬í•œ', 'eye-ëˆˆë°‘ì§€-ì•½ê°„', 'eye-ëˆˆë°‘ì§€-ì—†ìŒ', 'eye-ë™ê³µ-ì‚¬ë°±ì•ˆ', 'eye-ë™ê³µ-ë³´í†µ', 'eye-ë™ê³µ-ì‚¼ë°±ì•ˆ', 'eye-ë™ê³µ-ë°˜ê°€ë ¤ì§'],
        "2ì°¨ - ì½”": ['nose-ëª¨ì–‘-í™”ì‚´ì½”', 'nose-ëª¨ì–‘-ë³´í†µ', 'nose-ëª¨ì–‘-ë³µì½”', 'nose-ëª¨ì–‘-ë“¤ì°½ì½”', 'nose-ê¸¸ì´-ê¸´', 'nose-ê¸¸ì´-ë³´í†µ', 'nose-ê¸¸ì´-ì§§ì€', 'nose-ì½§ëŒ€-ë‘êº¼ìš´', 'nose-ì½§ëŒ€-ë³´í†µ', 'nose-ì½§ëŒ€-ì–‡ì€', 'nose-ì½§ë³¼-ë„“ì€', 'nose-ì½§ë³¼-ë³´í†µ', 'nose-ì½§ë³¼-ì¢ì€', 'nose-ì½”ë-ë„“ì€', 'nose-ì½”ë-ë³´í†µ', 'nose-ì½”ë-ì¢ì€', 'nose-ì½§êµ¬ë©-ë„“ì€', 'nose-ì½§êµ¬ë©-ë³´í†µ', 'nose-ì½§êµ¬ë©-ê¸´', 'nose-ì½§êµ¬ë©-ì¢ì€'],
        "2ì°¨ - ì…": ['mouth-ë„ˆë¹„-ë„“ì€', 'mouth-ë„ˆë¹„-ë³´í†µ', 'mouth-ë„ˆë¹„-ì¢ì€', 'mouth-ë‘ê»˜-ë‘êº¼ìš´', 'mouth-ë‘ê»˜-ë³´í†µ', 'mouth-ë‘ê»˜-ì–‡ì€', 'mouth-ì…ê¼¬ë¦¬-ì˜¬ë¼ê°„', 'mouth-ì…ê¼¬ë¦¬-í‰í‰í•œ', 'mouth-ì…ê¼´-ë‚´ë ¤ê°„', 'mouth-ìœ„ë‘ê»˜-ë‘êº¼ìš´', 'mouth-ìœ„ë‘ê»˜-ë³´í†µ', 'mouth-ìœ„ë‘ê»˜-ì–‡ì€', 'mouth-ì•„ë˜ë‘ê»˜-ë‘êº¼ìš´', 'mouth-ì•„ë˜ë‘ê»˜-ë³´í†µ', 'mouth-ì•„ë˜ë‘ê»˜-ì–‡ì€', 'mouth-ì „ì²´ì…ìˆ ì„ -ë˜ë ·', 'mouth-ì „ì²´ì…ìˆ ì„ -ë³´í†µ', 'mouth-ì „ì²´ì…ìˆ ì„ -íë¦¿', 'mouth-íí”¼ë“œ-ë˜ë ·', 'mouth-íí”¼ë“œ-ë‘¥ê¸€', 'mouth-íí”¼ë“œ-1ì', 'mouth-ì…ìˆ ê²°ì ˆ-ë¾°ì¡±', 'mouth-ì…ìˆ ê²°ì ˆ-1ì', 'mouth-ì…ìˆ ê²°ì ˆ-í•¨ëª°', 'mouth-ìœ„ê¸´ì¥ë„-ìˆìŒ', 'mouth-ìœ„ê¸´ì¥ë„-ë³´í†µ', 'mouth-ìœ„ê¸´ì¥ë„-ì—†ìŒ', 'mouth-ì•„ë˜ê¸´ì¥ë„-ìˆìŒ', 'mouth-ì•„ë˜ê¸´ì¥ë„-ë³´í†µ', 'mouth-ì•„ë˜ê¸´ì¥ë„-ì—†ìŒ', 'mouth-ì¸ì¤‘ê¸¸ì´-ì§§ì•„', 'mouth-ì¸ì¤‘ê¸¸ì´-ë³´í†µ', 'mouth-ì¸ì¤‘ê¸¸ì´-ê¸¸ì–´', 'mouth-ì¸ì¤‘ë„ˆë¹„-ë„“ì–´', 'mouth-ì¸ì¤‘ë„ˆë¹„-ë³´í†µ', 'mouth-ì¸ì¤‘ë„ˆë¹„-ì¢ì•„', 'mouth-íŒ”ì-ê¹Šì€', 'mouth-íŒ”ì-ë³´í†µ', 'mouth-íŒ”ì-ì—†ìŒ'],
        "2ì°¨ - ìœ¤ê³½": ['silhouette-ì–¼êµ´í˜•-ë‹¬ê±€í˜•', 'silhouette-ì–¼êµ´í˜•-ì—­ì‚¼ê°í˜•', 'silhouette-ì–¼êµ´í˜•-ê¸´', 'silhouette-ì–¼êµ´í˜•-ë™ê¸€', 'silhouette-ì–¼êµ´í˜•-ì‚¬ê°í˜•', 'silhouette-ì˜†ê´‘ëŒ€-í¬ê¸°-í°', 'silhouette-ì˜†ê´‘ëŒ€-í¬ê¸°-ë³´í†µ', 'silhouette-ì˜†ê´‘ëŒ€-í¬ê¸°-ì‘ì€', 'silhouette-ì˜†ê´‘ëŒ€-ë†’ì´-ë†’ì€', 'silhouette-ì˜†ê´‘ëŒ€-ë†’ì´-ë³´í†µ', 'silhouette-ì˜†ê´‘ëŒ€-ë†’ì´-ë‚®ì€', 'silhouette-ì˜†ê´‘ëŒ€-ìœ„ì¹˜-ë°–', 'silhouette-ì˜†ê´‘ëŒ€-ìœ„ì¹˜-ë³´í†µ', 'silhouette-ì˜†ê´‘ëŒ€-ìœ„ì¹˜-ì•ˆ', 'silhouette-ì•ê´‘ëŒ€-í¬ê¸°-í°', 'silhouette-ì•ê´‘ëŒ€-í¬ê¸°-ë³´í†µ', 'silhouette-ì•ê´‘ëŒ€-í¬ê¸°-ì‘ì€', 'silhouette-ì•ê´‘ëŒ€-ë†’ì´-ë†’ì€', 'silhouette-ì•ê´‘ëŒ€-ë†’ì´-ë³´í†µ', 'silhouette-ì•ê´‘ëŒ€-ë†’ì´-ë‚®ì€', 'silhouette-í„±-ë°œë‹¬-ë°œë‹¬', 'silhouette-í„±-ë°œë‹¬-ë³´í†µ', 'silhouette-í„±-ë°œë‹¬-ë¬´í„±', 'silhouette-í„±-í˜•íƒœ-ë¾°ì¡±í•œ', 'silhouette-í„±-í˜•íƒœ-ë³´í†µ', 'silhouette-í„±-í˜•íƒœ-ê°ì§„', 'silhouette-í„±-ê¸¸ì´-ê¸´', 'silhouette-í„±-ê¸¸ì´-ë³´í†µ', 'silhouette-í„±-ê¸¸ì´-ì§§ì€', 'silhouette-ë³¼-ì‚´-ì‚´X', 'silhouette-ë³¼-ì‚´-ë³´í†µ', 'silhouette-ë³¼-ì‚´-ì‚´O', 'silhouette-ë³¼-íƒ„ë ¥-ì³ì§„', 'silhouette-ë³¼-íƒ„ë ¥-ë³´í†µ', 'silhouette-ë³¼-íƒ„ë ¥-íƒ„ë ¥'],
    }


def analyze_tag_relationships(landmarks_data):
    """íƒœê·¸ ê°„ ê´€ê³„ ë¶„ì„"""
    tag_groups = get_tag_groups()

    # íƒœê·¸ ë ˆë²¨ë³„ ë¶„ë¥˜
    abstract_tags = set()
    primary_tags = set()
    secondary_tags = set()

    for group_name, tags in tag_groups.items():
        if group_name.startswith("ì¶”ìƒ"):
            abstract_tags.update(tags)
        elif group_name.startswith("1ì°¨"):
            primary_tags.update(tags)
        elif group_name.startswith("2ì°¨"):
            secondary_tags.update(tags)

    # ê´€ê³„ ë¶„ì„
    abstract_to_primary = {}
    primary_to_secondary = {}
    abstract_to_secondary = {}

    for _, row in landmarks_data.iterrows():
        if 'tags' in row and row['tags']:
            row_tags = row['tags'] if isinstance(row['tags'], list) else []

            # í•´ë‹¹ í–‰ì˜ íƒœê·¸ë“¤ì„ ë ˆë²¨ë³„ë¡œ ë¶„ë¥˜
            row_abstract = [tag for tag in row_tags if tag in abstract_tags]
            row_primary = [tag for tag in row_tags if tag in primary_tags]
            row_secondary = [tag for tag in row_tags if tag in secondary_tags]

            # ì¶”ìƒ â†’ 1ì°¨ ê´€ê³„
            for abs_tag in row_abstract:
                for prim_tag in row_primary:
                    key = (abs_tag, prim_tag)
                    abstract_to_primary[key] = abstract_to_primary.get(key, 0) + 1

            # 1ì°¨ â†’ 2ì°¨ ê´€ê³„
            for prim_tag in row_primary:
                for sec_tag in row_secondary:
                    key = (prim_tag, sec_tag)
                    primary_to_secondary[key] = primary_to_secondary.get(key, 0) + 1

            # ì¶”ìƒ â†’ 2ì°¨ ê´€ê³„ (ì§ì ‘ ì—°ê²°)
            for abs_tag in row_abstract:
                for sec_tag in row_secondary:
                    key = (abs_tag, sec_tag)
                    abstract_to_secondary[key] = abstract_to_secondary.get(key, 0) + 1

    return {
        'abstract_to_primary': abstract_to_primary,
        'primary_to_secondary': primary_to_secondary,
        'abstract_to_secondary': abstract_to_secondary,
        'abstract_tags': list(abstract_tags),
        'primary_tags': list(primary_tags),
        'secondary_tags': list(secondary_tags)
    }


def sort_by_frequency(tags, relationships, is_source=True):
    """íƒœê·¸ë“¤ì„ ê´€ê³„ ë¹ˆë„ìˆœìœ¼ë¡œ ì •ë ¬"""
    tag_frequency = {}

    for (source_tag, target_tag), count in relationships.items():
        if is_source:
            # source íƒœê·¸ì˜ ì´ ë¹ˆë„ ê³„ì‚°
            if source_tag in tags:
                tag_frequency[source_tag] = tag_frequency.get(source_tag, 0) + count
        else:
            # target íƒœê·¸ì˜ ì´ ë¹ˆë„ ê³„ì‚°
            if target_tag in tags:
                tag_frequency[target_tag] = tag_frequency.get(target_tag, 0) + count

    # ë¹ˆë„ìˆœìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ìˆœ)
    sorted_tags = sorted(tags, key=lambda x: tag_frequency.get(x, 0), reverse=True)
    return sorted_tags


def execute_single_tag_analysis(landmarks_data, selected_tag, point1, point2, calc_type):
    """ë‹¨ì¼ íƒœê·¸ ë¶„ì„ ì‹¤í–‰"""
    st.write("### ğŸ”„ ë¶„ì„ ì‹¤í–‰ ì¤‘...")

    # ì„ íƒëœ íƒœê·¸ë¥¼ ê°€ì§„ ë°ì´í„° í•„í„°ë§
    tag_data = []
    all_data = []
    names_with_tag = []
    names_all = []

    for _, row in landmarks_data.iterrows():
        try:
            # ëœë“œë§ˆí¬ ë°ì´í„° íŒŒì‹±
            if isinstance(row['landmarks'], str):
                landmarks = json.loads(row['landmarks'])
            else:
                landmarks = row['landmarks']

            # ì¸¡ì •ê°’ ê³„ì‚°
            measurement = calculate_length(landmarks, point1, point2, calc_type)

            if measurement is not None:
                all_data.append(measurement)
                names_all.append(row['name'])

                # ì„ íƒëœ íƒœê·¸ë¥¼ ê°€ì§„ ë°ì´í„°ì¸ì§€ í™•ì¸
                if 'tags' in row and row['tags']:
                    row_tags = row['tags'] if isinstance(row['tags'], list) else []
                    if selected_tag in row_tags:
                        tag_data.append(measurement)
                        names_with_tag.append(row['name'])

        except Exception as e:
            continue

    if not tag_data:
        st.error(f"'{selected_tag}' íƒœê·¸ë¥¼ ê°€ì§„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í†µê³„ ê³„ì‚°
    tag_mean = np.mean(tag_data)
    tag_std = np.std(tag_data)
    tag_q1, tag_q3 = np.percentile(tag_data, [25, 75])

    all_mean = np.mean(all_data)
    all_std = np.std(all_data)

    # ê²½ê³„ê°’ ì œì•ˆ (Q1 ê¸°ì¤€)
    boundary_suggestion = tag_q1

    # ê²°ê³¼ í‘œì‹œ
    st.write("### ğŸ“Š ë¶„ì„ ê²°ê³¼")

    # ìƒë‹¨ ë©”íŠ¸ë¦­
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ë¶„ì„ íƒœê·¸", selected_tag)
    with col2:
        st.metric("íƒœê·¸ ë°ì´í„°", f"{len(tag_data)}ê°œ")
    with col3:
        st.metric("ì „ì²´ ë°ì´í„°", f"{len(all_data)}ê°œ")
    with col4:
        st.metric("ì œì•ˆ ê²½ê³„ê°’", f"{boundary_suggestion:.1f}")

    # ë°•ìŠ¤í”Œë¡¯ ìƒì„±
    col1, col2 = st.columns([2, 1])

    with col1:
        # ë°ì´í„° ì¤€ë¹„
        plot_data = []
        for val in tag_data:
            plot_data.append({'value': val, 'group': f'{selected_tag} ({len(tag_data)}ê°œ)'})
        for val in all_data:
            plot_data.append({'value': val, 'group': f'ì „ì²´ ë°ì´í„° ({len(all_data)}ê°œ)'})

        plot_df = pd.DataFrame(plot_data)

        fig = px.box(
            plot_df,
            x='group',
            y='value',
            title=f'{selected_tag} vs ì „ì²´ ë°ì´í„° ë¶„í¬',
            labels={'value': f'ì¸¡ì •ê°’ ({calc_type})', 'group': 'ê·¸ë£¹'}
        )

        # ê²½ê³„ì„  ì¶”ê°€
        fig.add_hline(y=boundary_suggestion, line_dash="dash", line_color="red",
                     annotation_text=f"ì œì•ˆ ê²½ê³„ê°’: {boundary_suggestion:.1f}")

        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.write("#### ğŸ“ˆ íƒœê·¸ ê·¸ë£¹ í†µê³„")
        st.write(f"**í‰ê· :** {tag_mean:.2f}")
        st.write(f"**í‘œì¤€í¸ì°¨:** {tag_std:.2f}")
        st.write(f"**Q1:** {tag_q1:.2f}")
        st.write(f"**Q3:** {tag_q3:.2f}")

        st.write("#### ğŸ“ˆ ì „ì²´ ë°ì´í„° í†µê³„")
        st.write(f"**í‰ê· :** {all_mean:.2f}")
        st.write(f"**í‘œì¤€í¸ì°¨:** {all_std:.2f}")

        # ì°¨ì´ ë¶„ì„
        mean_diff = tag_mean - all_mean
        st.write("#### ğŸ” ì°¨ì´ ë¶„ì„")
        st.write(f"**í‰ê·  ì°¨ì´:** {mean_diff:+.2f}")

        if abs(mean_diff) > all_std:
            st.success("âœ… ì˜ë¯¸ìˆëŠ” ì°¨ì´ (1Ïƒ ì´ìƒ)")
        else:
            st.warning("âš ï¸ ì‘ì€ ì°¨ì´ (1Ïƒ ë¯¸ë§Œ)")

    # ê²½ê³„ê°’ ì œì•ˆ
    st.write("### ğŸ¯ ê²½ê³„ê°’ ì œì•ˆ")
    col1, col2, col3 = st.columns(3)

    with col1:
        st.write("**ë³´ìˆ˜ì  ê¸°ì¤€ (Q1)**")
        st.write(f"{tag_q1:.1f} ì´ìƒ")
        st.write(f"ì •í™•ë„: ~75%")

    with col2:
        st.write("**ì¤‘ê°„ ê¸°ì¤€ (í‰ê· )**")
        st.write(f"{tag_mean:.1f} ì´ìƒ")
        st.write(f"ì •í™•ë„: ~50%")

    with col3:
        st.write("**ê´€ëŒ€í•œ ê¸°ì¤€ (Q3)**")
        st.write(f"{tag_q3:.1f} ì´ìƒ")
        st.write(f"ì •í™•ë„: ~25%")

    # ìƒì„¸ ë°ì´í„°
    with st.expander("ğŸ“‹ ìƒì„¸ ë°ì´í„° ë³´ê¸°"):
        detail_df = pd.DataFrame({
            'íŒŒì¼ëª…': names_with_tag,
            'ì¸¡ì •ê°’': tag_data
        })
        detail_df = detail_df.sort_values('ì¸¡ì •ê°’', ascending=False)
        st.dataframe(detail_df, use_container_width=True)


def execute_level_comparison_analysis(landmarks_data, selected_feature, point1, point2, calc_type):
    """ë ˆë²¨ë³„ ë¹„êµ ë¶„ì„ ì‹¤í–‰"""
    st.write("### ğŸ”„ ë¹„êµ ë¶„ì„ ì‹¤í–‰ ì¤‘...")

    # í•´ë‹¹ íŠ¹ì„±ì˜ ëª¨ë“  ë ˆë²¨ íƒœê·¸ ì°¾ê¸°
    tag_groups = get_tag_groups()
    feature_levels = {}

    for group_name, tags in tag_groups.items():
        if group_name.startswith("2ì°¨"):
            for tag in tags:
                if tag.startswith(selected_feature + "-"):
                    level = tag.split('-')[-1]
                    feature_levels[level] = tag

    # ê° ë ˆë²¨ë³„ ë°ì´í„° ìˆ˜ì§‘
    level_data = {}
    level_names = {}

    for level, full_tag in feature_levels.items():
        level_data[level] = []
        level_names[level] = []

        for _, row in landmarks_data.iterrows():
            try:
                # ëœë“œë§ˆí¬ ë°ì´í„° íŒŒì‹±
                if isinstance(row['landmarks'], str):
                    landmarks = json.loads(row['landmarks'])
                else:
                    landmarks = row['landmarks']

                # ì¸¡ì •ê°’ ê³„ì‚°
                measurement = calculate_length(landmarks, point1, point2, calc_type)

                if measurement is not None:
                    # í•´ë‹¹ ë ˆë²¨ íƒœê·¸ë¥¼ ê°€ì§„ ë°ì´í„°ì¸ì§€ í™•ì¸
                    if 'tags' in row and row['tags']:
                        row_tags = row['tags'] if isinstance(row['tags'], list) else []
                        if full_tag in row_tags:
                            level_data[level].append(measurement)
                            level_names[level].append(row['name'])

            except Exception as e:
                continue

    # ë°ì´í„°ê°€ ìˆëŠ” ë ˆë²¨ë§Œ í•„í„°ë§
    valid_levels = {level: data for level, data in level_data.items() if len(data) > 0}

    if len(valid_levels) < 2:
        st.error("ë¹„êµí•  ìˆ˜ ìˆëŠ” ë ˆë²¨ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. (ìµœì†Œ 2ê°œ ë ˆë²¨ í•„ìš”)")
        return

    # ê²°ê³¼ í‘œì‹œ
    st.write("### ğŸ“Š ë ˆë²¨ë³„ ë¹„êµ ê²°ê³¼")

    # ìƒë‹¨ ë©”íŠ¸ë¦­
    cols = st.columns(len(valid_levels))
    level_stats = {}

    for i, (level, data) in enumerate(valid_levels.items()):
        level_mean = np.mean(data)
        level_stats[level] = {
            'mean': level_mean,
            'std': np.std(data),
            'q1': np.percentile(data, 25),
            'q3': np.percentile(data, 75),
            'count': len(data)
        }

        with cols[i]:
            st.metric(
                level,
                f"í‰ê·  {level_mean:.1f}",
                f"{len(data)}ê°œ"
            )

    # ë°•ìŠ¤í”Œë¡¯ ìƒì„±
    col1, col2 = st.columns([2, 1])

    with col1:
        # ë°ì´í„° ì¤€ë¹„
        plot_data = []
        for level, data in valid_levels.items():
            for val in data:
                plot_data.append({
                    'value': val,
                    'level': f'{level} ({len(data)}ê°œ)'
                })

        plot_df = pd.DataFrame(plot_data)

        fig = px.box(
            plot_df,
            x='level',
            y='value',
            title=f'{selected_feature} ë ˆë²¨ë³„ ë¶„í¬ ë¹„êµ',
            labels={'value': f'ì¸¡ì •ê°’ ({calc_type})', 'level': 'ë ˆë²¨'}
        )

        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.write("#### ğŸ“ˆ ë ˆë²¨ë³„ í†µê³„")
        for level, stats in level_stats.items():
            st.write(f"**{level}**")
            st.write(f"í‰ê· : {stats['mean']:.2f}")
            st.write(f"Q1-Q3: {stats['q1']:.1f} - {stats['q3']:.1f}")
            st.write("---")

    # ê²½ê³„ê°’ ì œì•ˆ
    st.write("### ğŸ¯ ë ˆë²¨ë³„ ê²½ê³„ê°’ ì œì•ˆ")

    # ë ˆë²¨ì„ í‰ê· ê°’ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_levels = sorted(level_stats.items(), key=lambda x: x[1]['mean'])

    if len(sorted_levels) >= 2:
        # ì¸ì ‘í•œ ë ˆë²¨ ê°„ ê²½ê³„ê°’ ê³„ì‚°
        boundaries = []
        for i in range(len(sorted_levels) - 1):
            level1_name, level1_stats = sorted_levels[i]
            level2_name, level2_stats = sorted_levels[i + 1]

            # ì¤‘ê°„ê°’ìœ¼ë¡œ ê²½ê³„ ì„¤ì •
            boundary = (level1_stats['q3'] + level2_stats['q1']) / 2
            boundaries.append({
                'lower_level': level1_name,
                'upper_level': level2_name,
                'boundary': boundary
            })

        for boundary_info in boundaries:
            st.write(f"**{boundary_info['lower_level']} vs {boundary_info['upper_level']}**")
            st.write(f"ì œì•ˆ ê²½ê³„ê°’: {boundary_info['boundary']:.1f}")
            st.write(f"â€¢ {boundary_info['boundary']:.1f} ë¯¸ë§Œ: {boundary_info['lower_level']}")
            st.write(f"â€¢ {boundary_info['boundary']:.1f} ì´ìƒ: {boundary_info['upper_level']}")
            st.write("---")

    # ìƒì„¸ ë°ì´í„°
    with st.expander("ğŸ“‹ ë ˆë²¨ë³„ ìƒì„¸ ë°ì´í„°"):
        for level, data in valid_levels.items():
            st.write(f"#### {level} ë ˆë²¨")
            detail_df = pd.DataFrame({
                'íŒŒì¼ëª…': level_names[level],
                'ì¸¡ì •ê°’': data
            })
            detail_df = detail_df.sort_values('ì¸¡ì •ê°’', ascending=False)
            st.dataframe(detail_df, use_container_width=True)