"""
Face Coordinate Analyzer
ì‹¤ì‹œê°„ ì¢Œí‘œ ê³„ì‚° ê¸°ë°˜ ì–¼êµ´ ë¶„ì„ í”Œë«í¼
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import json
import numpy as np
from pathlib import Path
from collections import Counter
from itertools import combinations

# Database
from database.db_manager import db_manager

# Utils modules
from utils.landmark_calculator import calculate_landmarks_metric, calculate_length
from utils.data_analyzer import execute_length_based_analysis
from utils.tag_processor import (
    get_tag_groups,
    analyze_tag_relationships,
    execute_single_tag_analysis,
    execute_level_comparison_analysis
)
from utils.visualization import create_sankey_diagram

# Page config
st.set_page_config(
    page_title="Face Coordinate Analyzer",
    page_icon="ğŸ­",
    layout="wide"
)


def main():
    st.title("ğŸ­ Face Coordinate Analyzer")
    st.markdown("**ì‹¤ì‹œê°„ ì¢Œí‘œ ê³„ì‚° ê¸°ë°˜ ì–¼êµ´ ë¶„ì„ í”Œë«í¼**")

    # ì‚¬ì´ë“œë°”ì— ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ê¸°ëŠ¥ ì¶”ê°€
    render_database_management_sidebar()

    # ëœë“œë§ˆí¬ ë°ì´í„° ë¡œë“œ
    landmarks_data = load_landmarks_data()

    # íƒ­ ìƒì„±
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ§® ì¢Œí‘œ ë¶„ì„", "ğŸ”— íƒœê·¸ ì—°ê´€ì„± ë¶„ì„", "ğŸŒŠ íƒœê·¸ ê´€ê³„ë„", "ğŸ“Š íƒœê·¸-ìˆ˜ì¹˜ ë¶„ì„"])

    with tab1:
        render_landmarks_analysis_tab(landmarks_data)

    with tab2:
        render_tag_analysis_tab(landmarks_data)

    with tab3:
        render_sankey_diagram_tab(landmarks_data)

    with tab4:
        render_tag_analysis_tab_new(landmarks_data)


def load_landmarks_data():
    """ëœë“œë§ˆí¬ ë°ì´í„° ë¡œë“œ"""
    # DBì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    db_data = db_manager.get_dataframe()

    if db_data.empty:
        st.sidebar.warning("ğŸ’¡ DBì— ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    # landmarks ì»¬ëŸ¼ì´ ìˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§
    landmarks_data = db_data[db_data['landmarks'].notna()].copy()

    if landmarks_data.empty:
        st.sidebar.warning("ğŸ’¡ landmarksê°€ í¬í•¨ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    # JSON íŒŒì¼ì—ì„œ ì¶”ê°€ ë°ì´í„° ë¡œë“œ ë° ë³‘í•©
    json_files_path = Path("json_files")
    json_data_list = []
    if json_files_path.exists():
        for file_path in json_files_path.glob("*.json"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    json_data = json.load(f)
                    # 'landmarks' ë°ì´í„°ê°€ ë¬¸ìì—´ì´ë©´ íŒŒì‹±
                    if isinstance(json_data.get('landmarks'), str):
                        json_data['landmarks'] = json.loads(json_data['landmarks'])
                    json_data_list.append(json_data)
            except Exception as e:
                st.error(f"'{file_path.name}' íŒŒì¼ ë¡œë”© ì˜¤ë¥˜: {e}")

    json_df = pd.DataFrame(json_data_list)

    # 3. ë°ì´í„° ë³‘í•©
    if not json_df.empty:
        # DB ë°ì´í„°ì™€ JSON ë°ì´í„°ë¥¼ í•©ì¹˜ê³ , 'name'ì„ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±° (JSON íŒŒì¼ ìš°ì„ )
        combined_data = pd.concat([landmarks_data, json_df], ignore_index=True)
        combined_data.drop_duplicates(subset=['name'], keep='last', inplace=True)
        landmarks_data = combined_data

    return landmarks_data


def render_landmarks_analysis_tab(landmarks_data):
    """ì¢Œí‘œ ë¶„ì„ íƒ­ ë Œë”ë§"""
    st.header("ğŸ§® ì¢Œí‘œ ë¶„ì„ (ì‹¤ì‹œê°„ ê³„ì‚°)")
    st.markdown("ë‘ ê±°ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë¹„êµ ë¶„ì„")

    if landmarks_data.empty:
        st.warning("ğŸ’¡ landmarksê°€ í¬í•¨ëœ JSON íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    st.sidebar.success(f"ğŸ“ {len(landmarks_data)}ê°œ ë°ì´í„° ë¡œë“œë¨")

    # 1. ê³„ì‚° ëª©ì  ì„ íƒ (ë‹¨ìˆœí™”)
    st.sidebar.write("### 1. ê³„ì‚° ëª©ì ")
    purpose = st.sidebar.selectbox(
        "ë¶„ì„ ëª©ì ì„ ì„ íƒí•˜ì„¸ìš”:",
        ["ğŸ“ ê±°ë¦¬ ì¸¡ì •", "âš–ï¸ ë¹„ìœ¨ ê³„ì‚°"],
        index=1
    )

    # 2. ê¸¸ì´1 ì„¤ì •
    st.sidebar.write("### 2. ê¸¸ì´1 ì„¤ì •(xì¶•)")
    col1, col2, col3 = st.sidebar.columns([1, 1, 1.2])

    with col1:
        l1_p1 = st.number_input("ì 1", min_value=0, max_value=491, value=33, key="l1_p1")
    with col2:
        l1_p2 = st.number_input("ì 2", min_value=0, max_value=491, value=133, key="l1_p2")
    with col3:
        l1_calc = st.selectbox("ê³„ì‚°ë°©ì‹", ["ì§ì„ ê±°ë¦¬", "Xì¢Œí‘œê±°ë¦¬", "Yì¢Œí‘œê±°ë¦¬"], key="l1_calc")

    # 3. ê¸¸ì´2 ì„¤ì • (ë¹„ìœ¨ ê³„ì‚°ì¼ ë•Œë§Œ)
    if purpose == "âš–ï¸ ë¹„ìœ¨ ê³„ì‚°":
        st.sidebar.write("### 3. ê¸¸ì´2 ì„¤ì •(yì¶•)")
        col1, col2, col3 = st.sidebar.columns([1, 1, 1.2])

        with col1:
            l2_p1 = st.number_input("ì 1", min_value=0, max_value=491, value=1, key="l2_p1")
        with col2:
            l2_p2 = st.number_input("ì 2", min_value=0, max_value=491, value=18, key="l2_p2")
        with col3:
            l2_calc = st.selectbox("ê³„ì‚°ë°©ì‹", ["ì§ì„ ê±°ë¦¬", "Xì¢Œí‘œê±°ë¦¬", "Yì¢Œí‘œê±°ë¦¬"], key="l2_calc")

        # 4. ì¶”ê°€ ì˜µì…˜
        st.sidebar.write("### 4. ì¶”ê°€ ì˜µì…˜")
        normalize_ratio = st.sidebar.checkbox("ì •ê·œí™” (xì¶•=1 ê³ ì •)", value=True)
        swap_axes = st.sidebar.checkbox("ì¶• ë°”ê¾¸ê¸° (xâ†”y)")
    else:
        # ê±°ë¦¬ ì¸¡ì •ì¼ ë•ŒëŠ” ê¸¸ì´2 ì„¤ì • ë¶ˆí•„ìš”
        l2_p1, l2_p2, l2_calc = None, None, None
        normalize_ratio = False
        swap_axes = False

    # 5. íƒœê·¸ í•˜ì´ë¼ì´íŠ¸ ê¸°ëŠ¥
    st.sidebar.write("### 5. íƒœê·¸ í•˜ì´ë¼ì´íŠ¸")
    enable_tag_highlight = st.sidebar.checkbox("íƒœê·¸ë³„ ìƒ‰ìƒ êµ¬ë¶„ í™œì„±í™”")

    selected_tags = []
    if enable_tag_highlight:
        # í˜„ì¬ ë°ì´í„°ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ íƒœê·¸ë“¤ ì¶”ì¶œ
        all_tags = set()
        for _, row in landmarks_data.iterrows():
            if 'tags' in row and row['tags']:
                tags = row['tags'] if isinstance(row['tags'], list) else []
                all_tags.update(tags)

        if all_tags:
            selected_tags = st.sidebar.multiselect(
                "í•˜ì´ë¼ì´íŠ¸í•  íƒœê·¸ ì„ íƒ:",
                sorted(list(all_tags)),
                help="ì„ íƒí•œ íƒœê·¸ë¥¼ ê°€ì§„ ë°ì´í„°ë§Œ ìƒ‰ìƒìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤."
            )

    # 6. ì‹¤í–‰ ë²„íŠ¼
    if st.sidebar.button("ğŸ”„ ë¶„ì„ ì‹¤í–‰", type="primary"):
        execute_length_based_analysis(
            landmarks_data, l1_p1, l1_p2, l1_calc, l2_p1, l2_p2, l2_calc, purpose,
            normalize_ratio, swap_axes, enable_tag_highlight, selected_tags
        )


def render_tag_analysis_tab(landmarks_data):
    """íƒœê·¸ ì—°ê´€ì„± ë¶„ì„ íƒ­ ë Œë”ë§"""
    st.header("ğŸ”— íƒœê·¸ ì—°ê´€ì„± ë¶„ì„")

    if landmarks_data.empty:
        st.warning("ğŸ’¡ íƒœê·¸ê°€ í¬í•¨ëœ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # íƒœê·¸ ë°ì´í„°ë§Œ í•„í„°ë§
    tag_data = landmarks_data[landmarks_data['tags'].notna()].copy()

    if tag_data.empty:
        st.warning("ğŸ’¡ íƒœê·¸ê°€ í¬í•¨ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì •ì˜ëœ íƒœê·¸ ê·¸ë£¹ê³¼ ì‹¤ì œ ë°ì´í„°ì˜ íƒœê·¸ ë¹„êµ
    tag_groups = get_tag_groups()
    data_tags = set()
    defined_tags = set()
    for group_tags in tag_groups.values():
        defined_tags.update(group_tags)

    for _, row in tag_data.iterrows():
        if isinstance(row['tags'], list):
            data_tags.update(row['tags'])

    all_unique_tags = sorted(list(data_tags.union(defined_tags)))

    st.write(f"### ğŸ“Š íƒœê·¸ í˜„í™©")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì •ì˜ëœ íƒœê·¸", len(defined_tags))
    with col2:
        st.metric("ë°ì´í„° íƒœê·¸", len(data_tags))
    with col3:
        st.metric("ì „ì²´ ê³ ìœ  íƒœê·¸", len(all_unique_tags))

    # íƒœê·¸ ì¡°í•© ë¶„ì„
    st.write("### ğŸ”„ íƒœê·¸ ì¡°í•© ë¶„ì„")

    # ì¡°í•© ê¸¸ì´ ì„ íƒ
    combination_length = st.selectbox(
        "ë¶„ì„í•  ì¡°í•© ê¸¸ì´:",
        [2, 3, 4, 5],
        index=0
    )

    if st.button("ì¡°í•© ë¶„ì„ ì‹¤í–‰"):
        tag_combinations = []

        for _, row in tag_data.iterrows():
            if isinstance(row['tags'], list) and len(row['tags']) >= combination_length:
                # í•´ë‹¹ ê¸¸ì´ì˜ ëª¨ë“  ì¡°í•© ìƒì„±
                for combo in combinations(row['tags'], combination_length):
                    tag_combinations.append(combo)

        if tag_combinations:
            # ì¡°í•© ë¹ˆë„ ê³„ì‚°
            combination_counts = Counter(tag_combinations)

            # ìƒìœ„ ì¡°í•© í‘œì‹œ
            st.write(f"#### ğŸ† ìƒìœ„ {combination_length}ê°œ íƒœê·¸ ì¡°í•©")

            top_combinations = combination_counts.most_common(20)
            combo_data = []

            for combo, count in top_combinations:
                combo_data.append({
                    'ì¡°í•©': ' + '.join(combo),
                    'ë¹ˆë„': count,
                    'ë¹„ìœ¨': f"{count/len(tag_data)*100:.1f}%"
                })

            combo_df = pd.DataFrame(combo_data)
            st.dataframe(combo_df, use_container_width=True)

            # íˆíŠ¸ë§µ ìƒì„± (2ê°œ ì¡°í•©ì¸ ê²½ìš°)
            if combination_length == 2 and len(top_combinations) > 5:
                st.write("#### ğŸŒ¡ï¸ íƒœê·¸ ì—°ê´€ì„± íˆíŠ¸ë§µ")

                # ìƒìœ„ íƒœê·¸ë“¤ ì¶”ì¶œ
                top_tags = set()
                for combo, count in top_combinations[:15]:  # ìƒìœ„ 15ê°œ ì¡°í•©ì—ì„œ íƒœê·¸ ì¶”ì¶œ
                    top_tags.update(combo)

                top_tags = sorted(list(top_tags))

                # íˆíŠ¸ë§µ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                matrix = []
                for tag1 in top_tags:
                    row = []
                    for tag2 in top_tags:
                        if tag1 == tag2:
                            count = combination_counts.get((tag1,), 0)  # ìê¸° ìì‹ ì€ ë‹¨ì¼ íƒœê·¸ ë¹ˆë„
                        else:
                            # ë‘ íƒœê·¸ì˜ ì¡°í•© ë¹ˆë„ (ìˆœì„œ ë¬´ê´€)
                            count = combination_counts.get((tag1, tag2), 0) + combination_counts.get((tag2, tag1), 0)
                        row.append(count)
                    matrix.append(row)

                if matrix and len(top_tags) > 1:
                    fig_heatmap = px.imshow(
                        matrix,
                        x=top_tags,
                        y=top_tags,
                        title="íƒœê·¸ ê°„ ì—°ê´€ì„± ê°•ë„",
                        labels=dict(color="ì¡°í•© ë¹ˆë„")
                    )
                    fig_heatmap.update_layout(height=600)
                    st.plotly_chart(fig_heatmap, use_container_width=True)

        else:
            st.warning(f"ê¸¸ì´ {combination_length}ì˜ íƒœê·¸ ì¡°í•©ì´ ì—†ìŠµë‹ˆë‹¤.")


def render_sankey_diagram_tab(landmarks_data):
    """Sankey ë‹¤ì´ì–´ê·¸ë¨ íƒ­ ë Œë”ë§"""
    st.header("ğŸŒŠ íƒœê·¸ ê´€ê³„ë„ (Sankey Diagram)")

    if landmarks_data.empty:
        st.warning("ğŸ’¡ íƒœê·¸ê°€ í¬í•¨ëœ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # íƒœê·¸ ê´€ê³„ ë¶„ì„
    relationships = analyze_tag_relationships(landmarks_data)

    if not any(relationships.values()):
        st.warning("ğŸ’¡ íƒœê·¸ ê´€ê³„ë¥¼ ë¶„ì„í•  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # í•„í„° ì˜µì…˜ - ë©”ì¸ í˜ì´ì§€ì— ë°°ì¹˜
    st.write("### ğŸ›ï¸ ë‹¤ì´ì–´ê·¸ë¨ ì„¤ì •")

    col1, col2, col3 = st.columns(3)

    with col1:
        # ê´€ê³„ íƒ€ì… ì„ íƒ
        relationship_type = st.selectbox(
            "í‘œì‹œí•  ê´€ê³„:",
            ["ì „ì²´ íë¦„ (ì¶”ìƒâ†’1ì°¨â†’2ì°¨)", "ì¶”ìƒâ†’1ì°¨ë§Œ", "1ì°¨â†’2ì°¨ë§Œ"]
        )

    with col2:
        # ìµœì†Œ ë¹ˆë„ ì„¤ì •
        min_frequency = st.slider(
            "ìµœì†Œ ê´€ê³„ ë¹ˆë„:",
            min_value=1,
            max_value=10,
            value=2,
            help="ì´ ë¹ˆë„ ì´ìƒì˜ ê´€ê³„ë§Œ í‘œì‹œí•©ë‹ˆë‹¤."
        )

    with col3:
        # íƒœê·¸ í•„í„° (ê´€ê³„ íƒ€ì…ì— ë”°ë¼) - ë‹¤ì¤‘ ì„ íƒ ì§€ì›
        if relationship_type in ["ì „ì²´ íë¦„ (ì¶”ìƒâ†’1ì°¨â†’2ì°¨)", "ì¶”ìƒâ†’1ì°¨ë§Œ"]:
            selected_abstract_tags = st.multiselect(
                "ì¶”ìƒ íƒœê·¸ í•„í„°:",
                relationships['abstract_tags'],
                default=[],
                help="ë¹ˆ ì„ íƒ ì‹œ ì „ì²´ íƒœê·¸ í‘œì‹œ"
            )
            # ë¹ˆ ì„ íƒì‹œ "ì „ì²´"ë¡œ ì²˜ë¦¬
            selected_abstract_tag = selected_abstract_tags if selected_abstract_tags else "ì „ì²´"
        elif relationship_type == "1ì°¨â†’2ì°¨ë§Œ":
            selected_primary_tags = st.multiselect(
                "1ì°¨ íƒœê·¸ í•„í„°:",
                relationships['primary_tags'],
                default=[],
                help="ë¹ˆ ì„ íƒ ì‹œ ì „ì²´ íƒœê·¸ í‘œì‹œ"
            )
            # ë¹ˆ ì„ íƒì‹œ "ì „ì²´"ë¡œ ì²˜ë¦¬
            selected_primary_tag = selected_primary_tags if selected_primary_tags else "ì „ì²´"
            selected_abstract_tag = "ì „ì²´"
        else:
            selected_abstract_tag = "ì „ì²´"
            selected_primary_tag = "ì „ì²´"

    # 1ì°¨â†’2ì°¨ë§Œì¸ ê²½ìš° selected_primary_tagê°€ ì •ì˜ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ ì„¤ì •
    if 'selected_primary_tag' not in locals():
        selected_primary_tag = "ì „ì²´"

    # Sankey ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
    create_sankey_diagram(
        relationships,
        selected_abstract_tag,
        min_frequency,
        relationship_type,
        selected_primary_tag
    )


def render_tag_analysis_tab_new(landmarks_data):
    """íƒœê·¸-ìˆ˜ì¹˜ ë¶„ì„ íƒ­ ë Œë”ë§"""
    st.header("ğŸ“Š íƒœê·¸-ìˆ˜ì¹˜ ë¶„ì„")

    if landmarks_data.empty:
        st.warning("ğŸ’¡ landmarksê°€ í¬í•¨ëœ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # ë¶„ì„ íƒ€ì… ì„ íƒ
    analysis_type = st.selectbox(
        "ë¶„ì„ íƒ€ì… ì„ íƒ:",
        ["ğŸ·ï¸ ë‹¨ì¼ íƒœê·¸ ë¶„ì„", "ğŸ“Š ë ˆë²¨ë³„ ë¹„êµ ë¶„ì„"]
    )

    if analysis_type == "ğŸ·ï¸ ë‹¨ì¼ íƒœê·¸ ë¶„ì„":
        render_single_tag_analysis(landmarks_data, 33, 133, "ì§ì„ ê±°ë¦¬")
    else:
        render_level_comparison_analysis(landmarks_data, 33, 133, "ì§ì„ ê±°ë¦¬")


def render_single_tag_analysis(landmarks_data, point1, point2, calc_type):
    """ë‹¨ì¼ íƒœê·¸ ë¶„ì„ ë Œë”ë§"""
    st.write("### ğŸ·ï¸ ë‹¨ì¼ íƒœê·¸ ë¶„ì„")
    st.write("íŠ¹ì • íƒœê·¸ë¥¼ ê°€ì§„ ë°ì´í„°ì˜ ì¸¡ì •ê°’ ë¶„í¬ë¥¼ ì „ì²´ ë°ì´í„°ì™€ ë¹„êµí•©ë‹ˆë‹¤.")

    # ì‚¬ìš© ê°€ëŠ¥í•œ íƒœê·¸ ì¶”ì¶œ
    all_tags = set()
    for _, row in landmarks_data.iterrows():
        if 'tags' in row and row['tags']:
            tags = row['tags'] if isinstance(row['tags'], list) else []
            all_tags.update(tags)

    if not all_tags:
        st.warning("ë¶„ì„í•  íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # íƒœê·¸ ì„ íƒ
    selected_tag = st.selectbox(
        "ë¶„ì„í•  íƒœê·¸ ì„ íƒ:",
        sorted(list(all_tags))
    )

    # ì¸¡ì • ì„¤ì •
    col1, col2, col3 = st.columns(3)
    with col1:
        point1 = st.number_input("ì¸¡ì •ì  1", min_value=0, max_value=491, value=point1)
    with col2:
        point2 = st.number_input("ì¸¡ì •ì  2", min_value=0, max_value=491, value=point2)
    with col3:
        calc_type = st.selectbox("ê³„ì‚° ë°©ì‹", ["ì§ì„ ê±°ë¦¬", "Xì¢Œí‘œê±°ë¦¬", "Yì¢Œí‘œê±°ë¦¬"], index=0)

    if st.button("ë‹¨ì¼ íƒœê·¸ ë¶„ì„ ì‹¤í–‰"):
        execute_single_tag_analysis(landmarks_data, selected_tag, point1, point2, calc_type)


def render_level_comparison_analysis(landmarks_data, point1, point2, calc_type):
    """ë ˆë²¨ë³„ ë¹„êµ ë¶„ì„ ë Œë”ë§"""
    st.write("### ğŸ“Š ë ˆë²¨ë³„ ë¹„êµ ë¶„ì„")
    st.write("2ì°¨ íƒœê·¸ì˜ ì„œë¡œ ë‹¤ë¥¸ ë ˆë²¨ ê°„ ì¸¡ì •ê°’ì„ ë¹„êµí•©ë‹ˆë‹¤.")

    # 2ì°¨ íƒœê·¸ì—ì„œ íŠ¹ì„± ì¶”ì¶œ
    tag_groups = get_tag_groups()
    features = set()

    for group_name, tags in tag_groups.items():
        if group_name.startswith("2ì°¨"):
            for tag in tags:
                if '-' in tag:
                    parts = tag.split('-')
                    if len(parts) >= 2:
                        feature = parts[1]  # ì˜ˆ: eye-í¬ê¸°-í° -> í¬ê¸°
                        features.add(feature)

    if not features:
        st.warning("ë¹„êµí•  2ì°¨ íƒœê·¸ íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # íŠ¹ì„± ì„ íƒ
    selected_feature = st.selectbox(
        "ë¹„êµí•  íŠ¹ì„± ì„ íƒ:",
        sorted(list(features))
    )

    # ì¸¡ì • ì„¤ì •
    col1, col2, col3 = st.columns(3)
    with col1:
        point1 = st.number_input("ì¸¡ì •ì  1", min_value=0, max_value=491, value=point1, key="level_p1")
    with col2:
        point2 = st.number_input("ì¸¡ì •ì  2", min_value=0, max_value=491, value=point2, key="level_p2")
    with col3:
        calc_type = st.selectbox("ê³„ì‚° ë°©ì‹", ["ì§ì„ ê±°ë¦¬", "Xì¢Œí‘œê±°ë¦¬", "Yì¢Œí‘œê±°ë¦¬"], index=0, key="level_calc")

    if st.button("ë ˆë²¨ë³„ ë¹„êµ ë¶„ì„ ì‹¤í–‰"):
        execute_level_comparison_analysis(landmarks_data, selected_feature, point1, point2, calc_type)


def render_database_management_sidebar():
    """ì‚¬ì´ë“œë°”ì— ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ê¸°ëŠ¥ ë Œë”ë§"""
    st.sidebar.write("### ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬")

    # JSON íŒŒì¼ ìŠ¤ìº”
    json_files_path = Path("json_files")
    if json_files_path.exists():
        json_files = list(json_files_path.glob("*.json"))

        if json_files:
            st.sidebar.write(f"ğŸ“ `json_files/`ì—ì„œ {len(json_files)}ê°œ íŒŒì¼ ë°œê²¬")

            # ë¯¸ë¦¬ë³´ê¸°
            with st.sidebar.expander("íŒŒì¼ ëª©ë¡ ë³´ê¸°"):
                for file_path in json_files[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                    st.write(f"â€¢ {file_path.name}")
                if len(json_files) > 5:
                    st.write(f"... ì™¸ {len(json_files) - 5}ê°œ")

            # ë°ì´í„°ë² ì´ìŠ¤ ì¶”ê°€ ë²„íŠ¼
            if st.sidebar.button("ğŸ”„ í´ë”-DB ë™ê¸°í™”",
                               help="json_files/ í´ë”ì™€ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì™„ì „íˆ ë™ê¸°í™”í•©ë‹ˆë‹¤. (ì¶”ê°€/ìˆ˜ì •/ì‚­ì œ ìë™ ì²˜ë¦¬)"):

                with st.spinner("í´ë”ì™€ DB ë™ê¸°í™” ì¤‘..."):
                    try:
                        # ìƒˆë¡œìš´ ë™ê¸°í™” ì‹œìŠ¤í…œ ì‚¬ìš©
                        sync_result = db_manager.sync_with_folder("json_files")

                        if "error" in sync_result:
                            st.sidebar.error(sync_result["error"])
                        else:
                            # ê²°ê³¼ í‘œì‹œ
                            st.sidebar.success(f"ğŸ”„ ë™ê¸°í™” ì™„ë£Œ!")

                            col1, col2 = st.sidebar.columns(2)
                            with col1:
                                st.metric("â• ì¶”ê°€", sync_result["added"], delta=sync_result["added"] if sync_result["added"] > 0 else None)
                                st.metric("âœï¸ ìˆ˜ì •", sync_result["updated"], delta=sync_result["updated"] if sync_result["updated"] > 0 else None)
                            with col2:
                                st.metric("ğŸ—‘ï¸ ì‚­ì œ", sync_result["deleted"], delta=-sync_result["deleted"] if sync_result["deleted"] > 0 else None)
                                st.metric("ğŸ“ ì´ íŒŒì¼", sync_result["total_files"])

                            if sync_result["added"] + sync_result["updated"] + sync_result["deleted"] == 0:
                                st.sidebar.info("ğŸ“Œ ëª¨ë“  ë°ì´í„°ê°€ ì´ë¯¸ ë™ê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                            else:
                                st.sidebar.info("âœ¨ json_files í´ë”ì™€ DBê°€ ì™„ì „íˆ ë™ê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")

                    except Exception as e:
                        st.sidebar.error(f"ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            st.sidebar.info("ğŸ“­ `json_files/` í´ë”ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    else:
        st.sidebar.info("ğŸ“ `json_files/` í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()